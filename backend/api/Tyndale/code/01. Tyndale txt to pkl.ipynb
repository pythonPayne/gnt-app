{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prepping BcvIndex and Word pickles from STEP repo...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "t0 = time.time()\n",
    "###############################################################################\n",
    "###############################################################################\n",
    "# NOTES\n",
    "# input: .txt files from STEP repo https://github.com/STEPBible/STEPBible-Data\n",
    "# output: .pkl files for Django models. See django-app/gnt/schema.py and models.py\n",
    "###############################################################################\n",
    "###############################################################################\n",
    "print(\"prepping BcvIndex and Word pickles from STEP repo...\")\n",
    "\n",
    "\n",
    "def tagnt_to_df(filename):\n",
    "    \"\"\"read TAGNT txt file from Tyndale repo into pandas dataframe\"\"\"\n",
    "    column_names = ['reference', 'wordType', 'greek', 'english', 'strongs', 'morphology', 'dictionaryForm', 'gloss',\n",
    "                    'editions', 'spellingVariants', 'meaningVariants', 'spanish', 'subMeaning', 'superMeaning', 'conjoin', 'word']\n",
    "    df = pd.read_csv(filename, sep='\\t', header=None,\n",
    "                     names=column_names, comment='#')\n",
    "    return df.dropna(subset=['greek'])\n",
    "\n",
    "\n",
    "# read GNT, word by word, from two .txt files in STEP repo -- Mat-Jhn, Act-Rev\n",
    "df1 = tagnt_to_df(\n",
    "    \"../data/TAGNT Mat-Jhn - Translators Amalgamated Greek NT - STEPBible.org CC-BY.txt\")\n",
    "df2 = tagnt_to_df(\n",
    "    \"../data/TAGNT Act-Rev - Translators Amalgamated Greek NT - STEPBible.org CC-BY.txt\")\n",
    "df = pd.concat([df1, df2]).reset_index(drop=True)\n",
    "df = df.fillna('')\n",
    "# for indexing, sorting\n",
    "df[\"id\"] = df.index\n",
    "df['book'] = df.reference.apply(lambda x: x.split('.')[0].split('_')[1])\n",
    "df['bookNum'] = df.reference.apply(lambda x: (\n",
    "    '0' + str(int(x.split('.')[0].split('_')[0])-40))[-2:])\n",
    "df['chapter'] = df.reference.apply(lambda x: x.split('.')[1][-2:])\n",
    "df['verse'] = df.reference.apply(lambda x: x.split('.')[2][-2:])\n",
    "df['bcv'] = df.bookNum + df.chapter + df.verse\n",
    "df['chapter'] = df.chapter.astype(int)\n",
    "df['verse'] = df.verse.astype(int)\n",
    "\n",
    "# figure out later what to do with missing values\n",
    "df[\"morphology\"] = df.morphology.apply(lambda x: 'MISSING' if x=='' else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###############################################################################\n",
    "###############################################################################\n",
    "# model: BcvIndex\n",
    "###############################################################################\n",
    "###############################################################################\n",
    "cols = ['bcv', 'book', 'chapter', 'verse']\n",
    "dg = df.groupby(cols).count().reset_index()[cols].sort_values(by='bcv')\n",
    "dg['bookLong'] = dg.book.apply(\n",
    "    lambda x: 'Matthew' if x == 'Mat' else\n",
    "              'Mark' if x == 'Mrk' else\n",
    "              'Luke' if x == 'Luk' else\n",
    "              'John' if x == 'Jhn' else\n",
    "              'Acts' if x == 'Act' else\n",
    "              'Romans' if x == 'Rom' else\n",
    "              '1 Corinthians' if x == '1Co' else\n",
    "              '2 Corinthians' if x == '2Co' else\n",
    "              'Galatians' if x == 'Gal' else\n",
    "              'Ephesians' if x == 'Eph' else\n",
    "              'Philippians' if x == 'Php' else\n",
    "              'Colossians' if x == 'Col' else\n",
    "              '1 Thessalonians' if x == '1Th' else\n",
    "              '2 Thessalonians' if x == '2Th' else\n",
    "              '1 Timothy' if x == '1Ti' else\n",
    "              '2 Timothy' if x == '2Ti' else\n",
    "              'Titus' if x == 'Tit' else\n",
    "              'Philemon' if x == 'Phm' else\n",
    "              'Hebrews' if x == 'Heb' else\n",
    "              'James' if x == 'Jas' else\n",
    "              '1 Peter' if x == '1Pe' else\n",
    "              '2 Peter' if x == '2Pe' else\n",
    "              '1 John' if x == '1Jn' else\n",
    "              '2 John' if x == '2Jn' else\n",
    "              '3 John' if x == '3Jn' else\n",
    "              'Jude' if x == 'Jud' else\n",
    "              'Revelation' if x == 'Rev' else \"flag\"\n",
    ")\n",
    "dg.to_pickle(\"../data/bcvIndex.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###############################################################################\n",
    "###############################################################################\n",
    "# model: Word ('_id' suffix to accomodate Django model relationships)\n",
    "###############################################################################\n",
    "###############################################################################\n",
    "df = df.rename(columns={\n",
    "    \"bcv\": \"bcvIndex_id\",\n",
    "    \"morphology\": \"morphology_id\",\n",
    "    \"strongs\": \"strongs_id\"\n",
    "}).drop(columns=['book', 'bookNum', 'chapter', 'verse'])\n",
    "df['bcv'] = df.bcvIndex_id\n",
    "df['nestleAland'] = df.wordType.apply(lambda x: True if x in [\n",
    "                                      \"=NA diff TR ˹˺\", \"=NA not TR ⁽⁾\", \"=NA same TR ~~\"] else False)\n",
    "df.to_pickle(\"../data/tagnt.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prepping Strongs pickle from STEP repo...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "###############################################################################\n",
    "###############################################################################\n",
    "# model: Strongs (5435 unique strongs_id in NT, merging with tbesg)\n",
    "###############################################################################\n",
    "###############################################################################\n",
    "print(\"prepping Strongs pickle from STEP repo...\")\n",
    "strongs_ids = df.groupby('strongs_id').count().reset_index(\n",
    ")[['strongs_id', 'bcv']].rename(columns={'bcv': 'frequency'})\n",
    "tbesg = pd.read_csv(\n",
    "    \"../data/TBESG - Translators Brief lexicon of Extended Strongs for Greek - STEPBible.org CC BY.txt\",\n",
    "    sep='\\t', header=None, skiprows=64,\n",
    "    names=['strongs_id', 'gloss', 'lexicon',\n",
    "           'transliteration', 'grammar', 'definitionhtml'],\n",
    "    comment='#',\n",
    ")\n",
    "df_strongs = strongs_ids.merge(tbesg, how='left', on='strongs_id')\n",
    "df_strongs = df_strongs.rename(columns={\n",
    "    \"strongs_id\": \"strongs\",\n",
    "})\n",
    "\n",
    "# Strongs model\n",
    "df_strongs.to_pickle(\"../data/strongs.pkl\")\n",
    "\n",
    "# List to json for gatsby-node to create only necessary pages\n",
    "# manually moved this file and added export statement\n",
    "# strongs_list = sorted(list(df_strongs.strongs.unique()))\n",
    "# with open('../../../../gatsby-app/src/data/strongsList.js', 'w') as f:\n",
    "#     json.dump(strongs_list, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prepping Morphology pickle from STEP repo...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "###############################################################################\n",
    "###############################################################################\n",
    "# model: Morphology\n",
    "###############################################################################\n",
    "###############################################################################\n",
    "print(\"prepping Morphology pickle from STEP repo...\")\n",
    "filename = '../data/TEGMC - Translators Expansion of Greek Morphhology Codes - STEPBible.org CC BY.txt'\n",
    "names = ['a', 'b']\n",
    "df = pd.read_csv(\n",
    "    filename,\n",
    "    sep='\\t',\n",
    "    skip_blank_lines=False,\n",
    "    skiprows=110,\n",
    "    header=None,\n",
    "    names=names,\n",
    ")\n",
    "\n",
    "# keep relevant lines\n",
    "df = df.iloc[:-19]\n",
    "df = df[df['a'] != '$'].reset_index(drop=True)\n",
    "num_parsings = int(df.shape[0]/4)\n",
    "line_list = []\n",
    "for i in range(num_parsings):\n",
    "    line_list.extend([1, 2, 3, 4])\n",
    "\n",
    "df['PARSING_LINE'] = line_list\n",
    "\n",
    "line1 = df[df['PARSING_LINE'] == 1].reset_index()[['a', 'b']]\\\n",
    "    .rename(columns={'a': 'MORPHOLOGY', 'b': 'LINE1'})\n",
    "line2 = df[df['PARSING_LINE'] == 2].reset_index()[['b']]\\\n",
    "    .rename(columns={'b': 'LINE2'})\n",
    "line3 = df[df['PARSING_LINE'] == 3].reset_index()[['b']]\\\n",
    "    .rename(columns={'b': 'LINE3'})\n",
    "line4 = df[df['PARSING_LINE'] == 4].reset_index()[['b']]\\\n",
    "    .rename(columns={'b': 'LINE4'})\n",
    "\n",
    "q = line1.join(line2).join(line3).join(line4)\n",
    "\n",
    "# get all parsing pieces as separate columns\n",
    "l1 = list(q['LINE1'])\n",
    "cols = []\n",
    "records = []\n",
    "for l in l1:\n",
    "    a = [i.strip() for i in l.split(';')]\n",
    "    b = [i.split('=')[0] for i in a]\n",
    "    c = [i.split('=')[1] for i in a]\n",
    "    record = {k: v for k, v in list(zip(b, c))}\n",
    "    records.append(record)\n",
    "    cols.extend(b)\n",
    "temp = pd.DataFrame(cols, columns=['a'])\n",
    "\n",
    "names1 = ['Function', 'Tense', 'Voice', 'Mood', 'Person', 'Case', 'Gender', 'Number', 'Form',\n",
    "          'Name type', 'Extra', 'Original language', 'Adj.Numb.', 'Indeclinable', 'Name in Original language']\n",
    "names2 = ['FUNCTION', 'TENSE', 'VOICE', 'MOOD', 'PERSON', 'CASE', 'GENDER', 'NUMBER', 'FORM',\n",
    "          'NAME_TYPE', 'EXTRA', 'ORIG_LANG', 'ADJ_NUMB', 'INDECLINABLE', 'NAME_IN_ORIG_LANG']\n",
    "renameDict = {k: v for k, v in list(zip(names1, names2))}\n",
    "\n",
    "r = pd.DataFrame(records)[names1].rename(columns=renameDict)\n",
    "colsKeep = ['MORPHOLOGY'] + names2\n",
    "z = q.join(r)[colsKeep]\n",
    "\n",
    "z = z.rename(columns={\n",
    "    \"MORPHOLOGY\": \"morphology\",\n",
    "    \"FUNCTION\": \"function\",\n",
    "    \"TENSE\": \"tense\",\n",
    "    \"VOICE\": \"voice\",\n",
    "    \"MOOD\": \"mood\",\n",
    "    \"PERSON\": \"person\",\n",
    "    \"CASE\": \"case\",\n",
    "    \"GENDER\": \"gender\",\n",
    "    \"NUMBER\": \"number\"\n",
    "})\n",
    "\n",
    "# figure out later what to do with missing values\n",
    "# for now...\n",
    "df = pd.read_pickle(\"../data/tagnt.pkl\")\n",
    "m = list(df.morphology_id.unique())\n",
    "missing_morphologies = [x for x in m if x not in list(z.morphology.unique())]\n",
    "# print(missing_morphologies)\n",
    "new_rows = []\n",
    "for morphology in missing_morphologies:\n",
    "    new_row = {}\n",
    "    new_row['morphology'] = morphology\n",
    "    new_row['function'] = ''\n",
    "    new_row['tense'] = ''\n",
    "    new_row['voice'] = ''\n",
    "    new_row['mood'] = ''\n",
    "    new_row['person'] = ''\n",
    "    new_row['case'] = ''\n",
    "    new_row['gender'] = ''\n",
    "    new_row['number'] = ''\n",
    "    new_rows.append(new_row)\n",
    "z2 = pd.DataFrame(new_rows) \n",
    "z = pd.concat([z,z2])\n",
    "\n",
    "# Morphology model\n",
    "z.to_pickle('../data/tegmc.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "249b2d0bd31f9fffee9a432bfa8ef53d594a6b6748a49d8f718f94d6a97b8acd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
