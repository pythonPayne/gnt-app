{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from duckdb import query\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.options.display.max_columns = 200\n",
    "pd.options.display.max_rows = 500\n",
    "pd.set_option('mode.chained_assignment', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = pd.read_pickle('../../pickles/word.pkl')\n",
    "pars = pd.read_pickle('../../pickles/pars.pkl')\n",
    "lexn = pd.read_pickle('../../pickles/lexn.pkl')\n",
    "pdgm = pd.read_pickle('../../pickles/pdgm.pkl')\n",
    "book = pd.read_pickle('../../pickles/book.pkl')\n",
    "chap = pd.read_pickle('../../pickles/chap.pkl')\n",
    "vers = pd.read_pickle('../../pickles/vers.pkl')\n",
    "frlc = pd.read_pickle('../../pickles/frlc.pkl')\n",
    "frlb = pd.read_pickle('../../pickles/frlb.pkl')\n",
    "gnt = pd.read_pickle('../../pickles/gnt.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for lexn_id in frlc.frlc_lexn_id.unique():\n",
    "    temp = frlc[frlc.frlc_lexn_id==lexn_id]\n",
    "    s = \"\"\n",
    "    for bk,ch in list(zip(temp.frlc_book_name_abbrev,temp.frlc_chap_num)):\n",
    "        s = s + \"|\" + bk + \"_\" + str(ch)\n",
    "    row = {\n",
    "        \"lexn_id\": lexn_id,\n",
    "        \"lexn_chs\": s[1:],\n",
    "        # \"len\": len(s)\n",
    "    }\n",
    "    rows.append(row)\n",
    "temp = pd.DataFrame(rows)    \n",
    "lexn = lexn.merge(temp, how='left', on='lexn_id')\n",
    "lexn.to_pickle(\"../../pickles/lexn.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=word[word.word_id.between('19010101','19010499')]\n",
    "df.head(10)[['word_greek','word_english','word_pars_id','word_lexn_id']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_to_back_words(w1, w2):\n",
    "    x = False\n",
    "    verses = []\n",
    "    for i,id in enumerate(word.word_lexn_id):\n",
    "        if id == w1:\n",
    "            x = True\n",
    "        elif x and id == w2:\n",
    "            x = False\n",
    "            verses.append(word.iloc[i].word_vers_id)\n",
    "        else:\n",
    "            x = False\n",
    "    return verses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexn_gloss_lookup(arr):\n",
    "    return list(lexn[lexn.lexn_gloss.isin(arr)].lexn_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_interlinear(vers_ids):\n",
    "    verses = []\n",
    "    for vers_id in vers_ids:\n",
    "        vers = gnt[gnt.vers_id==vers_id]        \n",
    "        vers_ref_abbrev = list(vers.vers_ref_abbrev.unique())[0]\n",
    "        verses.append([vers_ref_abbrev,]+[(word).replace('¶','') for word,punc in list(zip(vers.word_greek, vers.word_greek_punc))])\n",
    "        verses.append([vers_ref_abbrev,]+[(word).replace('¶','') for word,punc in list(zip(vers.word_english, vers.word_english_punc))])\n",
    "    df = pd.DataFrame(verses).fillna('')\n",
    "    df = df.rename(columns={n:f\"word_{n}\" for n in df.columns})\n",
    "    df = df.rename(columns={\"word_0\":\"vers_ref_abbrev\"})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexn_gloss_lookup(['to talk', 'to speak', 'to say'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexn_gloss_lookup(['God'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_interlinear(vers_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vers_ids = back_to_back_words('0000', '0114')\n",
    "vers_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vers1 = [(word + punc).replace('¶','') for word,punc in list(zip(vers.word_greek, vers.word_greek_punc))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verses = [vers1, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(verses).fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 64-bit ('venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0a29e89b845665d7d0789a8321d577e6c69fdc3d91ccd79449c46cb24170a134"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
